{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### para instalar skopt #######\n",
    "#!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Precisamos correr estas líneas en MAC para que ande el multiprocesamiento del crossvalidation###\n",
    "import multiprocessing as mp; mp.set_start_method('forkserver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para ignorar warnings (no funciona como esperaba, hay que darle una vuelta de rosca mas)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.pipeline import dataset_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import dill\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "#Librerias\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Classifiers\n",
    "#import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Optimizador bayesiano\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### LOAD DATASET CON PICKLE #######\n",
    "#### Este dataset ya tiene generado el preprocesamiento del texto #######\n",
    "pickle_file = open('./data/dataframe_preproc.pkl','rb')\n",
    "\n",
    "df = pickle.load(pickle_file)\n",
    "df = df.sample(frac=1, random_state=12).copy() # mezclo los datos para que los subsambling sean aleatorios\n",
    "pickle_file.close()\n",
    "\n",
    "df=df[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#instancio un pipeline y un clasificador RF, con los resultados obtenidos de la ejecución del optimizador\n",
    "data_set_pipeline = dataset_pipeline(LSA_K = 83,LDA_TOPICS = 214,max_df_tfidf=0.7, min_df_tfidf=0.3,\n",
    "                    max_df_cv=0.7 , min_df_cv=0.3)\n",
    "rf_clf = RandomForestClassifier(n_estimators=52, max_depth=6,max_features='sqrt',n_jobs=-1)\n",
    "clf_pipeline = Pipeline([(\"dataset\",data_set_pipeline)\n",
    "                         ,(\"clf\", rf_clf)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAME = \"preproc_text\"#\"raw_text\"\n",
    "CLASS_NAME = \"rating\"\n",
    "\n",
    "X = df[FEATURE_NAME]\n",
    "y = df[CLASS_NAME]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.isin([\"Buy cinema ticket\"]), test_size=0.20, random_state=42)\n",
    "#Entrenamiendo y testeo\n",
    "fit_pipeline=clf_pipeline.fit(X_train,y_train)\n",
    "test_predict_proba=clf_pipeline.predict_proba(X_test)\n",
    "test_predict=clf_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Armo el dataframe con las probabilidades predichas y la clase real\n",
    "df_test_pred_proba=DataFrame(test_predict_proba)\n",
    "df_test_pred_proba.columns=['false_prob','true_prob']\n",
    "df_test_pred_proba['tconst']=DataFrame(y_test).reset_index().tconst\n",
    "df_test_pred_proba['real_value']=DataFrame(y_test).reset_index().rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# veo los resultados del testing\n",
    "y_test_pred_pc=df_test_pred_proba.true_prob>0.3 #punto de corte seleccionado\n",
    "df_test_pred_proba.real_value\n",
    "confusion_matrix(df_test_pred_proba.real_value, y_test_pred_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df_test_pred_proba.real_value, y_test_pred_pc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(df_test_pred_proba.real_value, df_test_pred_proba.true_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_pred_proba.to_excel('rf_pred_3000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clf_evaluation(df_test_pred_proba.real_value, y_test_pred_pc,df_test_pred_proba.true_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#### distribucion de probabilidades\n",
    "df_test_pred_proba.groupby(\"real_value\")[\"true_prob\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix , roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot_clf_evaluation(y,y_pred_value,y_pred_proba, title=None):\n",
    "    \n",
    "    title=\"Random Forest\"\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_pred_proba)\n",
    "    roc_auc = roc_auc_score(y,y_pred_proba)\n",
    "    print(roc_auc)\n",
    "    label = \"AUC: %.2f\"%(roc_auc )\n",
    "\n",
    "    ax1.plot(fpr, tpr, label=label )\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.set_xlim([-0.05, 1.05])\n",
    "    ax1.set_ylim([-0.05, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "\n",
    "    cfn_matrix = confusion_matrix(y, y_pred_value)\n",
    "\n",
    "    cfn_matrix = cfn_matrix.astype(float) / cfn_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    sns.heatmap(cfn_matrix, annot=True, ax=ax2 , fmt=\".2f\", vmin=0, vmax=1, cmap=\"Blues\")\n",
    "    ax2.set_xticklabels([False,True])\n",
    "    ax2.set_yticklabels([False,True])\n",
    "    _=ax2.set_ylabel(\"True Values\")\n",
    "    _=ax2.set_xlabel(\"Predicted Values\")\n",
    "\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "\n",
    "############################\n",
    "#### distribucion de probabilidades\n",
    "\n",
    "\n",
    "#pred_df.groupby(\"real_values\")[\"True_prob\"].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#### SIMPLE CV Train\n",
    "\n",
    "FEATURE_NAME = \"preproc_text\"\n",
    "CLASS_NAME = \"rating\"\n",
    "\n",
    "X = df[FEATURE_NAME]\n",
    "y = df[CLASS_NAME]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.isin([\"Buy cinema ticket\"]), test_size=0.20, random_state=42)\n",
    "\n",
    "cv_results = cross_validate(clf_pipeline, X_train, y_train, scoring=[\"f1\",\"roc_auc\",\"accuracy\",\"recall\"], return_train_score=True)\n",
    "simple_cv_result_df = DataFrame(cv_results)\n",
    "simple_cv_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### OPTIMIZACION BAYESIANA\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "pickle_file_preproc = open('./data/dataframe_preproc.pkl','rb')\n",
    "df_preproc = pickle.load(pickle_file_preproc)\n",
    "df_preproc = df_preproc.sample(frac=1, random_state=12).copy() # mezclo los datos para que los subsambling sean aleatorios\n",
    "pickle_file_preproc.close()\n",
    "df_preproc=df_preproc[:3000]\n",
    "FEATURE_NAME = \"preproc_text\"#\"raw_text\"\n",
    "CLASS_NAME = \"rating\"\n",
    "\n",
    "\n",
    "X = df_preproc[FEATURE_NAME]\n",
    "y = df_preproc[CLASS_NAME]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.isin([\"Buy cinema ticket\"]), test_size=0.20, random_state=42)\n",
    "\n",
    "skopt_grid = { # se arma con los parametros  que se listan en la celda a continuacion\n",
    "\n",
    "'dataset__text_features__topics__tf_vec__max_df':Real(0.7,1.0),\n",
    "'dataset__text_features__topics__tf_vec__max_df':Real(0.0,0.3),\n",
    "###### LDA ###############\n",
    "'dataset__text_features__topics__topic_features__lda__learning_decay':Real(0.5, 1.0),\n",
    "'dataset__text_features__topics__topic_features__lda__max_iter': Integer(50, 500),\n",
    "'dataset__text_features__topics__topic_features__lda__n_components': Integer(100, 1000),\n",
    "#### RF parameters #####\n",
    "'clf__n_estimators': Integer(20, 200), \n",
    "'clf__max_depth': Integer(4, 12),\n",
    "'clf__max_depth': (\"auto\",\"sqrt\",\"log2\")\n",
    "}\n",
    "\n",
    "\n",
    "#Defino funcion de callback para ir guardando los resultados y bkp del optimizador\n",
    "def on_step(optim_result):\n",
    "    DataFrame(opt.cv_results_).to_excel(\"rf_opt_result_3000.xlsx\")\n",
    "    DataFrame(opt.grid_scores_).to_excel(\"rf_opt_grid_scores_3000.xlsx\")\n",
    "    pickle.dump( opt, open( \"rf_opt_skpot_2000.pkl\", \"wb\" ), protocol=2 )\n",
    "    score = opt.best_score_\n",
    "    print(\"best score: %s\" % score)\n",
    "\n",
    "\n",
    "\n",
    "# log-uniform: understand as search over p = exp(x) by varying x\n",
    "opt = BayesSearchCV(\n",
    "    clf_pipeline,\n",
    "    skopt_grid,\n",
    "    n_iter=100,n_jobs=-1,n_points=10,scoring=\"roc_auc\",cv=3\n",
    ")\n",
    "\n",
    "res = opt.fit(X_train, y_train,callback=on_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
